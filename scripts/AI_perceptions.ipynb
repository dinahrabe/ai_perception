{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Perceptions Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cleaning the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Reading the Corpus\n",
    "articles=pd.read_csv('../data/g_df', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article        11522\n",
       "liveblog         527\n",
       "video             27\n",
       "gallery           27\n",
       "audio             12\n",
       "picture           12\n",
       "interactive       11\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the articles in the corpus\n",
    "articles['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to articles of type 'article'\n",
    "article=articles[articles['type']=='article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for NA or NAN values in the column body_text and wordcount of 0\n",
    "article=article[article['wordcount']!=0]\n",
    "article=article[article['body_text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6814, 47)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check whether the API has queried the correct articles\n",
    "# filter the body_text column for the word 'machine learning' or 'AI' and put into a new dataframe\n",
    "query_check_df = article[article['body_text'].str.contains('machine learning|machine-learning|AI|artificial intelligence|artificial-intelligence|deep-learning|deep learning|intelligent machines|BERT|GPT-3|deep mind|DeepMind')]\n",
    "\n",
    "# check the length of the dataframe\n",
    "query_check_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/g_8v28y122j2fc_vq7b3x8cr0000gn/T/ipykernel_19129/951991710.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query_check_df[\"text\"]=query_check_df[\"body\"].astype(\"str\").apply(lambda x: clean_body(x))\n"
     ]
    }
   ],
   "source": [
    "#Cleaning html tags from the news articles' body\n",
    "from bs4 import BeautifulSoup\n",
    "#Function cleaning html tags\n",
    "def clean_body(html_text):\n",
    "    cleantext = BeautifulSoup(html_text, \"lxml\").text\n",
    "    return cleantext\n",
    "\n",
    "#Application to the dataframe\n",
    "query_check_df[\"text\"]=query_check_df[\"body\"].astype(\"str\").apply(lambda x: clean_body(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6814, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restarting the index to get the appropriate number of articles\n",
    "query_check_df=query_check_df.reset_index(drop=True)\n",
    "query_check_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/g_8v28y122j2fc_vq7b3x8cr0000gn/T/ipykernel_19129/4251740462.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  query_check_df['text'] = query_check_df['text'].str.replace('http\\S+|www.\\S+', '', case=False)\n"
     ]
    }
   ],
   "source": [
    "#Removing URLS and Emails from the dataset\n",
    "#Removing URLS starting with http or www.\n",
    "query_check_df['text'] = query_check_df['text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "#Removing Emails\n",
    "query_check_df['text'] = query_check_df['text'].replace('[\\w\\.-]+@[\\w\\.-]+', '', regex=True)\n",
    "#Removing URLS without http or www.\n",
    "query_check_df['text'] = query_check_df['text'].replace('[\\w\\.-]+\\.[\\w\\.-]+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing \"THE GUARDIAN\" from news' text\n",
    "query_check_df['text'] = query_check_df['text'].replace(\"THE GUARDIAN\", '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dinah/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "#Creating a copy of the dataframe with a column including the sentences per text\n",
    "q_df=query_check_df\n",
    "q_df[\"text_sentences\"]=query_check_df.text.apply(lambda x: tokenize.sent_tokenize(x))\n",
    "clean_articles=q_df.assign(sentence=q_df.text_sentences).explode('sentence')\n",
    "#clean_articles=query_check_df.assign(sentence=query_check_df.text.str.split(\".\")).explode('sentence')\n",
    "\n",
    "# Using the previous index to identify the article number and reseting the index\n",
    "clean_articles.index.name=\"article_nr\"\n",
    "clean_articles=clean_articles.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_nr</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>section_id</th>\n",
       "      <th>section_name</th>\n",
       "      <th>web_publication_date</th>\n",
       "      <th>web_title</th>\n",
       "      <th>web_url</th>\n",
       "      <th>api_url</th>\n",
       "      <th>is_hosted</th>\n",
       "      <th>...</th>\n",
       "      <th>display_hint</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sensitive</th>\n",
       "      <th>live_blogging_now</th>\n",
       "      <th>contributor_bio</th>\n",
       "      <th>allow_ugc</th>\n",
       "      <th>scheduled_publication_date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_sentences</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>316247</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>Then again, events will probably jolt the self...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316248</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>Around 2040, says Yorick Blumenfeld, a rare pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316249</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>So few people will have so much economic power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316250</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>Or maybe these islands will be invaded, by a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316251</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>Or, as British Telecom's Atlas of the Future c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316252</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>The millennium baby had better learn to use a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316253</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>21st-century life at a glance 2010: Entire hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316254</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>2020: Average lifespan in developed world reac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316255</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>2040: Satellite colonies successfully establis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316256</th>\n",
       "      <td>6813</td>\n",
       "      <td>world/2000/jan/01/millennium.uk1</td>\n",
       "      <td>article</td>\n",
       "      <td>us-news</td>\n",
       "      <td>US news</td>\n",
       "      <td>2000-01-01T01:54:17Z</td>\n",
       "      <td>Born to be wired</td>\n",
       "      <td>https://www.theguardian.com/world/2000/jan/01/...</td>\n",
       "      <td>https://content.guardianapis.com/world/2000/ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The baby born today, living an average life, a...</td>\n",
       "      <td>[The baby born today, living an average life, ...</td>\n",
       "      <td>2100: No clear distinction between humans and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_nr                                id     type section_id  \\\n",
       "316247        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316248        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316249        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316250        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316251        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316252        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316253        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316254        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316255        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "316256        6813  world/2000/jan/01/millennium.uk1  article    us-news   \n",
       "\n",
       "       section_name  web_publication_date         web_title  \\\n",
       "316247      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316248      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316249      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316250      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316251      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316252      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316253      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316254      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316255      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "316256      US news  2000-01-01T01:54:17Z  Born to be wired   \n",
       "\n",
       "                                                  web_url  \\\n",
       "316247  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316248  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316249  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316250  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316251  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316252  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316253  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316254  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316255  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "316256  https://www.theguardian.com/world/2000/jan/01/...   \n",
       "\n",
       "                                                  api_url  is_hosted  ...  \\\n",
       "316247  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316248  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316249  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316250  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316251  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316252  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316253  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316254  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316255  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "316256  https://content.guardianapis.com/world/2000/ja...      False  ...   \n",
       "\n",
       "       display_hint star_rating sensitive live_blogging_now contributor_bio  \\\n",
       "316247          NaN         NaN       NaN               NaN             NaN   \n",
       "316248          NaN         NaN       NaN               NaN             NaN   \n",
       "316249          NaN         NaN       NaN               NaN             NaN   \n",
       "316250          NaN         NaN       NaN               NaN             NaN   \n",
       "316251          NaN         NaN       NaN               NaN             NaN   \n",
       "316252          NaN         NaN       NaN               NaN             NaN   \n",
       "316253          NaN         NaN       NaN               NaN             NaN   \n",
       "316254          NaN         NaN       NaN               NaN             NaN   \n",
       "316255          NaN         NaN       NaN               NaN             NaN   \n",
       "316256          NaN         NaN       NaN               NaN             NaN   \n",
       "\n",
       "       allow_ugc scheduled_publication_date  \\\n",
       "316247       NaN                        NaN   \n",
       "316248       NaN                        NaN   \n",
       "316249       NaN                        NaN   \n",
       "316250       NaN                        NaN   \n",
       "316251       NaN                        NaN   \n",
       "316252       NaN                        NaN   \n",
       "316253       NaN                        NaN   \n",
       "316254       NaN                        NaN   \n",
       "316255       NaN                        NaN   \n",
       "316256       NaN                        NaN   \n",
       "\n",
       "                                                     text  \\\n",
       "316247  The baby born today, living an average life, a...   \n",
       "316248  The baby born today, living an average life, a...   \n",
       "316249  The baby born today, living an average life, a...   \n",
       "316250  The baby born today, living an average life, a...   \n",
       "316251  The baby born today, living an average life, a...   \n",
       "316252  The baby born today, living an average life, a...   \n",
       "316253  The baby born today, living an average life, a...   \n",
       "316254  The baby born today, living an average life, a...   \n",
       "316255  The baby born today, living an average life, a...   \n",
       "316256  The baby born today, living an average life, a...   \n",
       "\n",
       "                                           text_sentences  \\\n",
       "316247  [The baby born today, living an average life, ...   \n",
       "316248  [The baby born today, living an average life, ...   \n",
       "316249  [The baby born today, living an average life, ...   \n",
       "316250  [The baby born today, living an average life, ...   \n",
       "316251  [The baby born today, living an average life, ...   \n",
       "316252  [The baby born today, living an average life, ...   \n",
       "316253  [The baby born today, living an average life, ...   \n",
       "316254  [The baby born today, living an average life, ...   \n",
       "316255  [The baby born today, living an average life, ...   \n",
       "316256  [The baby born today, living an average life, ...   \n",
       "\n",
       "                                                 sentence  \n",
       "316247  Then again, events will probably jolt the self...  \n",
       "316248  Around 2040, says Yorick Blumenfeld, a rare pe...  \n",
       "316249  So few people will have so much economic power...  \n",
       "316250  Or maybe these islands will be invaded, by a p...  \n",
       "316251  Or, as British Telecom's Atlas of the Future c...  \n",
       "316252  The millennium baby had better learn to use a ...  \n",
       "316253  21st-century life at a glance 2010: Entire hum...  \n",
       "316254  2020: Average lifespan in developed world reac...  \n",
       "316255  2040: Satellite colonies successfully establis...  \n",
       "316256  2100: No clear distinction between humans and ...  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_articles.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316257, 51)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the length of the dataframe\n",
    "clean_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all articles that are not in English\n",
    "full_df=clean_articles[clean_articles['lang']=='en']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the dataframe to the columns article_nr, sentence, wordcount, section_name publication_date, web_publication_date, headline, web_title, production_office, publication\n",
    "final_df=clean_articles[['article_nr','sentence','wordcount','section_name','web_publication_date','headline','web_title','production_office','publication']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to file\n",
    "#full_df.to_csv('full_df.tsv', sep=\"\\t\")\n",
    "final_df.to_csv('final_df.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6813, 49)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_check_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all articles that are not in English from query_check_df\n",
    "query_check_df=query_check_df[query_check_df['lang']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_df = query_check_df[['body','body_text','wordcount','section_name','web_publication_date','headline','web_title','production_office','publication']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give all column names of the dataframe\n",
    "d_df.to_csv('d_df.tsv', sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "725a73563e8cb218d1bdef73fbe522cc2000c343f76cf85b0b96bd6c72a1fd0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
